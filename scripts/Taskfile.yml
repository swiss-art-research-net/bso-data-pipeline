# https://taskfile.dev

version: '3'

vars:
  ENDPOINT: http://blazegraph:8080/blazegraph/sparql
  GENERATOR_POLICY: /mapping/generator-policy.xml
  MAPPING_BATCH_SIZE: 10

tasks:

  default:
    desc: Runs the entire pipeline
    silent: true
    cmds:
      - task: prepare-xml-records-zbz
      - task: prepare-xml-records-nb
      - task: prepare-xml-records-sff
      - task: mapping-zbz
      - task: mapping-nb
      - task: mapping-sff
      - task: ingest-data-nb
      - task: ingest-data-zbz
      - task: ingest-data-sff
      - task: ingest-data-additional
      - task: ingest-classifications
      - task: ingest-ontologies
      - task: add-relations
      - task: add-summaries
      - task: cleanup


  add-relations:
    desc: Materialise triples defined through the queries/addRelations.sparql query in the Blazegraph instance
    cmds:
      - task: run-query-from-file
        vars: {FILE: "queries/addRelations.sparql"}

  add-summaries:
    desc: Materialise summaries for the entities
    cmds:
      - task: run-query-from-file
        vars: {FILE: "queries/addSummaries.sparql"}

  cache-thumbnails:
    cmds:
      - python /scripts/cache-thumbnails.py --endpoint {{.ENDPOINT}} {{if .FILTER_CONDITION}}--filterCondition {{.FILTER_CONDITION}}{{end}} --propsFile {{.PROPS_FILE}} --outputDir {{.OUTPUT_DIR}} --namedGraph {{.NAMED_GRAPH}} --thumbnailLocation $HOST_LOCATION{{.HOST_PATH}}
       
  cache-all-thumbnails:
    desc: Cache thumbnails of all entities
    cmds:
      - task: cache-thumbnails
        vars:
          ENDPOINT: http://blazegraph:8080/blazegraph/sparql
          HOST_PATH: /assets/no_auth
          OUTPUT_DIR: /apps/static/assets/no_auth
          NAMED_GRAPH: https://resource.swissartresearch.net/graph/thumbnails
          PROPS_FILE: /apps/bso/config/ui.prop      

  cache-wikidata-thumbnails:
    desc: Cache thumbnails of Wikidata entities
    cmds:
      - task: cache-thumbnails
        vars:
          ENDPOINT: http://blazegraph:8080/blazegraph/sparql
          FILTER_CONDITION: wdt:P18
          HOST_PATH: /assets/no_auth
          OUTPUT_DIR: /apps/static/assets/no_auth
          NAMED_GRAPH: https://resource.swissartresearch.net/graph/thumbnails
          PROPS_FILE: /apps/bso/config/ui.prop


  cleanup:
    desc: Run Cleanup query (located in queries/cleanup.sparql)
    cmds:
      - task: run-query-from-file
        vars: {FILE: "queries/cleanup.sparql"}

  delete-field-definitions:
    desc: Delete the field definitions stored in the database
    cmds:
      - task: run-query-from-file
        vars: {FILE: "queries/deleteFieldDefinitions.sparql"}

  delete-image-regions:
    desc: Delete the generated image regions from the Blazegraph instance
    cmds:
      - task: run-query-from-file
        vars: {FILE: "queries/deleteImageRegions.sparql"}

  download-iiif-manifests:
    desc: Downloads the IIIF Manifests found in the ZBZ data source file
    vars:
      IIIF_MANIFESTS_FROM: 0
      IIIF_MANIFEST_TO: 9999
    sources:
      - /data/source/zbz-doi.csv
    generates:
      - /data/manifests/*.json
    cmds:
      - python /scripts/cache-iiif-manifests.py {{.IIIF_MANIFESTS_FROM}} {{.IIIF_MANIFESTS_TO}}

  generate-dossier-thumbnails:
    desc: Generate thumbnails for the dossiers that contain (several) images
    vars:
      ENDPOINT: http://blazegraph:8080/blazegraph/sparql
      HOST_PATH: /assets/no_auth
      OUTPUT_DIR: /apps/static/assets/no_auth
      NAMED_GRAPH: https://resource.swissartresearch.net/graph/thumbnails/dossiers
    cmds:
      - python /scripts/generate-dossier-thumbnails.py --endpoint {{.ENDPOINT}} --outputDir {{.OUTPUT_DIR}} --namedGraph {{.NAMED_GRAPH}} --thumbnailLocation $HOST_LOCATION{{.HOST_PATH}}

  generate-iiif-manifests:
    desc: Generates IIIF Manifests based on the data present in the triple store
    cmds:
      - python /scripts/generate-iiif-manifests.py {{.IIIF_MANIFESTS_LIMIT}} {{.IIIF_MANIFESTS_OFFSET}}

  ingest-data-additional:
    desc: Ingest the TTL and Trig files located in the data/ttl/additional folder to the Blazegraph instance. 
    sources:
      - /data/ttl/additional/*.ttl
      - /data/ttl/additional/*.trig
    cmds:
      - echo "Ingest additional data"
      - task: ingest-data-from-folder
        vars: 
          FOLDER: /data/ttl/additional
          GRAPH: https://resource.swissartresearch.net/graph/external

  ingest-data-from-file:
    cmds:
      - echo "Ingest {{.NAME}}"
      - curl -X POST -H 'Content-Type:{{.TYPE}}' --data-binary '@{{.FILE}}' {{.ENDPOINT}}?context-uri={{.GRAPH}}

  ingest-data-from-folder:
    desc: Ingests data from a specified folder. If a named graph is specified (GRAPH), TTL files will be ingested into it. Otherwise, the filename will be used as named graph. Named Graphs specified in Trig files will be used as defined
    cmds:
      - |
        numfiles=$(ls -l {{.FOLDER}}/*.{ttl,trig} | wc -l)
        count=1
        # The graph is dropped before ingesting, except if some files have already been ingested
        {{if .GRAPH}}
        if [ $(ls -l {{.FOLDER}}/*.ingested 2>/dev/null | wc -l) -gt 0 ]; then
          echo "Some files have already been ingested. Skipping DROP GRAPH"
        else
          curl --silent -X POST {{.ENDPOINT}} --data-urlencode "update=DROP GRAPH <{{.GRAPH}}>" > /dev/null
        fi
        {{end}}
        for f in $(ls -1 {{.FOLDER}}/*.ttl); do
          echo "Ingesting file $count of $numfiles ($f)"
          curl --silent -X POST --data-binary "uri=file://$f" {{.ENDPOINT}}?context-uri={{if .GRAPH}}{{.GRAPH}}{{else}}file://$f{{end}} > /dev/null
          count=$((count+1))
          mv $f $f.ingested
        done
        for f in $(ls -1 {{.FOLDER}}/*.trig); do
          echo "Ingesting file $count of $numfiles ($f)"
          curl --silent -X POST --data-binary "uri=file://$f" {{.ENDPOINT}}{{if .GRAPH}}?context-uri={{.GRAPH}}{{end}} > /dev/null
          count=$((count+1)) 
        done
        for f in $(ls -1 {{.FOLDER}}/*.ingested); do
          mv $f ${f%.ingested}
        done

  ingest-data-main:
    desc: Ingest the TTL files located in the data/ttl/main folder to the Blazegraph instance
    sources:
      - /data/ttl/main/*/*.ttl
    cmds:
      - echo "Ingest main data"
      - task: ingest-data-nb
      - task: ingest-data-zbz
      - task: ingest-data-sff

  ingest-data-nb:
    desc: Ingest the TTL files located in the data/ttl/main/nb folder to the Blazegraph instance
    sources:
      - /data/ttl/main/nb/*.ttl
    cmds:
      - task: ingest-data-from-folder
        vars: 
          FOLDER: /data/ttl/main/nb
          GRAPH: https://resource.swissartresearch.net/graph/nb

  ingest-data-nb-as-individual-graphs:
    desc: Ingest the TTL files located in the data/ttl/main/nb folder to the Blazegraph instance, placing each file into an individual named graph
    sources:
      - /data/ttl/main/nb/*.ttl
    cmds:
      - task: ingest-data-from-folder
        vars: 
          FOLDER: /data/ttl/main/nb

  ingest-data-sff:
    desc: Ingest the TTL files located in the data/ttl/main/sff folder to the Blazegraph instance
    sources:
      - /data/ttl/main/sff/*.ttl
    cmds:
      - task: ingest-data-from-folder
        vars: 
          FOLDER: /data/ttl/main/sff
          GRAPH: https://resource.swissartresearch.net/graph/sff

  ingest-data-sff-as-individual-graphs:
    desc: Ingest the TTL files located in the data/ttl/main/sff folder to the Blazegraph instance, placing each file into an individual named graph
    sources:
      - /data/ttl/main/sff/*.ttl
    cmds:
      - task: ingest-data-from-folder
        vars: 
          FOLDER: /data/ttl/main/sff

  ingest-data-zbz:
    desc: Ingest the TTL files located in the data/ttl/main/zbz folder to the Blazegraph instance
    sources:
      - /data/ttl/main/zbz/*.ttl
    cmds:
      - task: ingest-data-from-folder
        vars: 
          FOLDER: /data/ttl/main/zbz
          GRAPH: https://resource.swissartresearch.net/graph/zbz

  ingest-data-zbz-as-individual-graphs:
    desc: Ingest the TTL files located in the data/ttl/main/zbz folder to the Blazegraph instance, placing each file into an individual named graph
    sources:
      - /data/ttl/main/zbz/*.ttl
    cmds:
      - task: ingest-data-from-folder
        vars: 
          FOLDER: /data/ttl/main/zbz

  ingest-ontologies:
    desc: Ingests the ontologies into individual named Graphs
    cmds:
      - task: ingest-data-from-file
        vars:
          NAME: CIDOC-CRM
          FILE: /mapping/schemas/CIDOC_CRM_7.1.1_RDFS_Impl_v1.1.rdfs
          TYPE: application/rdf+xml
          GRAPH: http://www.cidoc-crm.org/cidoc-crm/
      - task: ingest-data-from-file
        vars:
          NAME: CRMdig
          FILE: /mapping/schemas/CRMdig_v3.2.1.rdfs
          TYPE: application/rdf+xml
          GRAPH: http://www.ics.forth.gr/isl/CRMdig/
      - task: ingest-data-from-file
        vars:
          NAME: CRMinf
          FILE: /mapping/schemas/CRMinf_v0.7_.rdfs
          TYPE: application/rdf+xml
          GRAPH: http://www.ics.forth.gr/isl/CRMinf/
      - task: ingest-data-from-file
        vars:
          NAME: FRBRoo
          FILE: /mapping/schemas/FRBR2.4.rdfs
          TYPE: application/rdf+xml
          GRAPH: http://iflastandards.info/ns/fr/frbr/frbroo/

  ingest-classifications:
    desc: Ingest the calculated similarities and other classifications
    sources:
      - /data/graphs/titleSimilarities.ttl
      - /data/graphs/visualSimilarities.ttl
      - /data/graphs
    cmds:
      - task: ingest-title-similarities
      - task: ingest-visual-similarities
      - task: ingest-color-schemes
      #- task: ingest-distances

  ingest-color-schemes:
    desc: Ingests the color schemes into the Blazegraph instance
    sources:
      - /data/graphs/colorSchemes.ttl
    vars:
      GRAPH: https://resource.swissartresearch.net/graph/colorSchemes
    cmds:
      - curl --silent -X POST {{.ENDPOINT}} --data-urlencode "update=DROP GRAPH <{{.GRAPH}}>" > /dev/null
      - task: ingest-data-from-file
        vars:
          NAME: Color Schemes
          TYPE: text/turtle
          FILE: /data/graphs/colorSchemes.ttl
          GRAPH: https://resource.swissartresearch.net/graph/colorSchemes

  ingest-distances:
    desc: Ingest computed distances between entities into the Blazegraph instance
    sources:
      - /data/graphs/distances-*.ttl
    vars:
      GRAPH: https://resource.swissartresearch.net/graph/distances
    cmds:
      - curl --silent -X POST {{.ENDPOINT}} --data-urlencode "update=DROP GRAPH <{{.GRAPH}}>" > /dev/null
      - task: ingest-data-from-file
        vars:
          NAME: Distances
          TYPE: text/turtle
          FILE: /data/graphs/distances-birth_date_dist.ttl
          GRAPH: https://resource.swissartresearch.net/graph/distances
      - task: ingest-data-from-file
        vars:
          NAME: Distances
          TYPE: text/turtle
          FILE: /data/graphs/distances-birth_years_dist.ttl
          GRAPH: https://resource.swissartresearch.net/graph/distances
      - task: ingest-data-from-file
        vars:
          NAME: Distances
          TYPE: text/turtle
          FILE: /data/graphs/distances-ceation_role.ttl
          GRAPH: https://resource.swissartresearch.net/graph/distances
      - task: ingest-data-from-file
        vars:
          NAME: Distances
          TYPE: text/turtle
          FILE: /data/graphs/distances-creation_dist.ttl
          GRAPH: https://resource.swissartresearch.net/graph/distances
      - task: ingest-data-from-file
        vars:
          NAME: Distances
          TYPE: text/turtle
          FILE: /data/graphs/distances-death_date_dist.ttl
          GRAPH: https://resource.swissartresearch.net/graph/distances
      - task: ingest-data-from-file
        vars:
          NAME: Distances
          TYPE: text/turtle
          FILE: /data/graphs/distances-death_years_dist.ttl
          GRAPH: https://resource.swissartresearch.net/graph/distances
      - task: ingest-data-from-file
        vars:
          NAME: Distances
          TYPE: text/turtle
          FILE: /data/graphs/distances-labels_dist.ttl
          GRAPH: https://resource.swissartresearch.net/graph/distances
      - task: ingest-data-from-file
        vars:
          NAME: Distances
          TYPE: text/turtle
          FILE: /data/graphs/distances-production_dist.ttl
          GRAPH: https://resource.swissartresearch.net/graph/distances
      - task: ingest-data-from-file
        vars:
          NAME: Distances
          TYPE: text/turtle
          FILE: /data/graphs/distances-production_obj_dist.ttl
          GRAPH: https://resource.swissartresearch.net/graph/distances
      - task: ingest-data-from-file
        vars:
          NAME: Distances
          TYPE: text/turtle
          FILE: /data/graphs/distances-production_role_dist.ttl
          GRAPH: https://resource.swissartresearch.net/graph/distances
      - task: ingest-data-from-file
        vars:
          NAME: Distances
          TYPE: text/turtle
          FILE: /data/graphs/distances-visitem_dist.ttl
          GRAPH: https://resource.swissartresearch.net/graph/distances

  ingest-title-similarities:
    desc: Ingests the title similarities into the Blazegraph instance
    sources:
      - /data/graphs/titleSimilarities.ttl
    vars:
      GRAPH: https://resource.swissartresearch.net/graph/titleSimilarities
    cmds:
      - curl --silent -X POST {{.ENDPOINT}} --data-urlencode "update=DROP GRAPH <{{.GRAPH}}>" > /dev/null
      - task: ingest-data-from-file
        vars:
          NAME: Title Similarities
          TYPE: text/turtle
          FILE: /data/graphs/titleSimilarities.ttl
          GRAPH: https://resource.swissartresearch.net/graph/titleSimilarities

  ingest-visual-similarities:
    desc: Ingests the visual similarities into the Blazegraph instance
    sources:
      - /data/graphs/visualSimilarities.ttl
    vars:
      GRAPH: https://resource.swissartresearch.net/graph/visualSimilarities
    cmds:
      - curl --silent -X POST {{.ENDPOINT}} --data-urlencode "update=DROP GRAPH <{{.GRAPH}}>" > /dev/null
      - task: ingest-data-from-file
        vars:
          NAME: Visual Similarities
          TYPE: text/turtle
          FILE: /data/graphs/visualSimilarities.ttl
          GRAPH: https://resource.swissartresearch.net/graph/visualSimilarities

  
  mapping-nb:
    desc: Map SNB XML data to CIDOC/RDF
    vars:
      INPUT_FOLDER: /data/xml/nb
      OUTPUT_FOLDER: /data/ttl/main/nb
      MAPPING_FILE: /mapping/mappings-nb.x3ml
    sources:
      - /data/xml/nb/*.xml
      - /mapping/mappings-nb.x3ml
    generates:
      - /data/ttl/main/nb/*.ttl
    cmds:
      - rm -f {{.OUTPUT_FOLDER}}/*.ttl
      - bash /scripts/performMapping.sh -i {{.INPUT_FOLDER}} -o {{.OUTPUT_FOLDER}} -m {{.MAPPING_FILE}} -g {{.GENERATOR_POLICY}} -b {{.MAPPING_BATCH_SIZE}}

  mapping-sff:
    desc: Map SFF XML data to CIDOC/RDF
    vars:
      INPUT_FOLDER: /data/xml/sff
      OUTPUT_FOLDER: /data/ttl/main/sff
      MAPPING_FILE: /mapping/mappings-sff.x3ml
    sources:
      - /data/xml/sff/*.xml
      - /mapping/mappings-sff.x3ml
    generates:
      - /data/ttl/main/sff/*.ttl
    cmds:
      - rm -f {{.OUTPUT_FOLDER}}/*.ttl
      - bash /scripts/performMapping.sh -i {{.INPUT_FOLDER}} -o {{.OUTPUT_FOLDER}} -m {{.MAPPING_FILE}} -g {{.GENERATOR_POLICY}} -b {{.MAPPING_BATCH_SIZE}}

  mapping-zbz:
    desc: Map ZBZ XML data to CIDOC/RDF
    vars:
      INPUT_FOLDER: /data/xml/zbz
      OUTPUT_FOLDER: /data/ttl/main/zbz
      MAPPING_FILE: /mapping/mappings-zbz.x3ml
    sources:
      - /data/xml/zbz/*.xml
      - /mapping/mappings-zbz.x3ml
    generates:
      - /data/ttl/main/zbz/*.ttl
    cmds:
      - rm -f {{.OUTPUT_FOLDER}}/*.ttl
      - bash /scripts/performMapping.sh -i {{.INPUT_FOLDER}} -o {{.OUTPUT_FOLDER}} -m {{.MAPPING_FILE}} -g {{.GENERATOR_POLICY}} -b {{.MAPPING_BATCH_SIZE}}

  materialise-field-definitions:
    desc: Materialises the field definitions as propertes in the graph
    vars:
      FIELD_DEFINITIONS: /bso-app-src/fieldDefinitions.yml
      GRAPH: https://resource.swissartresearch.net/graph/fields
      QUERY:
        sh: python /scripts/generate-materialise-query-from-field-definitions.py {{.FIELD_DEFINITIONS}} {{.GRAPH}}
    cmds:
      - curl -X POST {{.ENDPOINT}} --data-urlencode "update={{.QUERY}}" 

  prepare-xml-records-nb:
    desc: Extract individual records from the NB data
    sources:
      - /data/source/nb-*.xml
      - /data/source/nb-*.csv
      - /scripts/prepare-xml-records-nb.py
    generates:
      - /data/xml/nb/*.xml
    cmds:
      - rm -f /data/xml/nb/*.xml
      - python /scripts/prepare-xml-records-nb.py {{.RECORDS_LIMIT}} {{.RECORDS_OFFSET}}

  prepare-xml-records-sff:
    desc: Extract individual records from the SFF data
    sources:
      - /data/source/sff-*.csv
      - /scripts/prepare-xml-records-sff.py
    generates:
      - /data/xml/sff/*.xml
    cmds:
      - rm -f /data/xml/sff/*.xml
      - python /scripts/prepare-xml-records-sff.py {{.RECORDS_LIMIT}} {{.RECORDS_OFFSET}}

  prepare-xml-records-zbz:
    desc: Convert the ZBZ data from JSON to individual XML Records
    sources:
      - /data/source/BIBLIOGRAPHIC_*.xml
      - /data/source/zbz-*.csv
      - /scripts/prepare-xml-records-zbz.py
      - /scripts/helpers/dateOverrides.py
    generates:
      - /data/xml/zbz/*.xml
    cmds:
      - rm -f /data/xml/zbz/*.xml
      - python /scripts/prepare-xml-records-zbz.py {{.RECORDS_LIMIT}} {{.RECORDS_OFFSET}}

  retrieve-aat:
    desc: Extracts relevant data from AAT based on identifiers found in the mapped TTL files
    sources:
      - /data/ttl/main/*.ttl
      - /scripts/retrieveAdditionalData.py
    generates:
      - /data/ttl/additional/aat.ttl
    cmds:
      - python retrieveAdditionalData.py --sourceFolder /data/ttl/main --targetFolder /data/ttl/additional --sources aat

  retrieve-additional-data:
    desc: Retrieve additional reference data for the mapped data
    sources:
      - /data/ttl/main/*.ttl
      - /scripts/retrieveAdditionalData.py
    generates:
      - /data/ttl/additional/aat.ttl
      - /data/ttl/additional/gnd.ttl
      - /data/ttl/additional/loc.ttl
      - /data/ttl/additional/wd.ttl
    cmds:
      - python retrieveAdditionalData.py --sourceFolder /data/ttl/main --targetFolder /data/ttl/additional --sources gnd,wd,aat,loc
      
  retrieve-loc:
    desc: Extracts relevant data from Library of Congress based on identifiers found in the mapped TTL files
    cmds:
      - python /scripts/extract-loc-data.py

  retrieve-gnd:
    desc: Extracts relevant data from GND based on identifiers found in the mapped TTL files
    sources:
      - /data/ttl/main/*.ttl
      - /scripts/retrieveAdditionalData.py
    generates:
      - /data/ttl/additional/gnd.ttl
    cmds:
      - python retrieveAdditionalData.py --sourceFolder /data/ttl/main --targetFolder /data/ttl/additional --sources gnd

  retrieve-wikidata:
    desc: Extracts relevant data from Wikidata based on identifiers found in the mapped TTL files
    sources:
      - /data/ttl/main/*.ttl
      - /scripts/retrieveAdditionalData.py
    generates:
      - /data/ttl/additional/wd.ttl
    cmds:
      - python retrieveAdditionalData.py --sourceFolder /data/ttl/main --targetFolder /data/ttl/additional --sources wd

  retrieve-wikimedia-image-rights:
    desc: Retrieve the image rights metadata for the extracted images from Wikimedia Commons
    sources:
      - /scripts/extract-wm-image-rights.py
      - /data/ttl/additional/wd.ttl
    generates:
      - /data/ttl/additional/wdRights.ttl
    cmds:
      - python /scripts/extract-wm-image-rights.py

  run-query-from-file:
    vars:
      QUERY:
        sh: cat {{.FILE}}
    cmds:
      - curl -X POST {{.ENDPOINT}} --data-urlencode "update={{.QUERY}}" 
  
  update-image-regions:
    desc: Updates the image regions from the provided Trig file. Regions that have been manually updated will are left unchanged
    sources:
      - /data/graphs/imageRegions.trig
    vars:
      INPUTFILE: /data/graphs/imageRegions.trig
      UPDATE_CONDITION: |
        PREFIX crm: <http://www.cidoc-crm.org/cidoc-crm/>                            
        PREFIX crmdig: <http://www.ics.forth.gr/isl/CRMdig/>
        ASK { 
          ?s a crmdig:D35_Area ;
              crm:P33_used_specific_technique <https://github.com/swiss-art-research-net/bso-image-segmentation> .
        }
      PREPROCESS_UPDATE: |
        DELETE { 
          ?container <http://www.w3.org/ns/prov#generatedAtTime> ?dateTime .
        } WHERE { 
            ?container a <http://www.w3.org/ns/ldp#Resource> ; 
              <http://www.w3.org/ns/prov#generatedAtTime> ?dateTime .
        }
    cmds:
      - python /scripts/update-named-graphs.py --inputfile {{.INPUTFILE}} --endpoint {{.ENDPOINT}} --updatecondition """{{.UPDATE_CONDITION}}""" --preprocessupdate """{{.PREPROCESS_UPDATE}}"""
      - task: run-query-from-file
        vars: {FILE: "queries/deleteGeneratedImageRegionIfAManualOneExists.sparql"}