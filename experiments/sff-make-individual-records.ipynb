{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import re\n",
    "import sys\n",
    "import unicodedata\n",
    "from lxml import etree\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputFile = '../data/source/SFF-Datenbank-Export.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "artistsFile = '../data/source/sff-curation-artists.csv'\n",
    "imagesFile = '../data/source/sff-images.csv'\n",
    "curatedFilesPre = '../data/source/sff-curation-'\n",
    "outputDirectory = '../data/xml/sff/'\n",
    "outputPrefix = 'sff-record-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "curatedFields = ['Keywords', 'Ortsbezug']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = 10\n",
    "offset = 20\n",
    "idsToOutput = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addArtistsData(record):\n",
    "    artistTagName = \"KünsterIn\"\n",
    "    artistValues = record.findall(artistTagName + '/values/value')\n",
    "    \n",
    "    # Curated data is added as is, except if the fields are specified here\n",
    "    fieldsToTreatSeparately = ['role', 'role_gnd']\n",
    "    \n",
    "    # Context is set as 'production' per default, except for\n",
    "    # roles specified here, where it is set to 'creation'\n",
    "    creationContext = ['Zeichner', 'Autor', 'Maler', 'Zeichnerin', 'Kartograph']\n",
    "    \n",
    "    for value in artistValues:\n",
    "        artistIdName = value.find('text').text\n",
    "        if not artistIdName:\n",
    "            return record\n",
    "        artistData = False\n",
    "        try:\n",
    "            allArtistData = [d for d in artistsData if d['id'] == artistIdName]\n",
    "        except:\n",
    "            print(\"Could not find artist data for\", artistIdName)\n",
    "            \n",
    "        if len(allArtistData) > 0:\n",
    "            for artistData in allArtistData:\n",
    "                for key in artistData.keys():\n",
    "                    if key not in fieldsToTreatSeparately:\n",
    "                        newElement = etree.SubElement(value, key)\n",
    "                        newElement.text = artistData[key]\n",
    "                if artistData['role']:\n",
    "                    roles = artistData['role'].split(', ')\n",
    "                    roles_gnd = artistData['role_gnd'].split(', ')\n",
    "                    rolesElement = etree.SubElement(value, 'roles')\n",
    "                    for i, role in enumerate(roles):\n",
    "                        roleElement = etree.SubElement(rolesElement, 'roleValue')\n",
    "                        roleElement.set('gnd', roles_gnd[i])\n",
    "                        roleElement.text = role\n",
    "                        if role in creationContext:\n",
    "                            value.set('creation', 'true')\n",
    "                        else:\n",
    "                            value.set('production', 'true')\n",
    "                        \n",
    "    return record\n",
    "\n",
    "def addCuratedData(record):\n",
    "    for curatedField in curatedFields:\n",
    "        tag = cleanKeyForTags(curatedField)\n",
    "        valueTags = record.findall(tag + '/values/value')\n",
    "        for valueTag in valueTags:\n",
    "            text = valueTag.find('text').text\n",
    "            lookupHash = customHash(text)\n",
    "            \n",
    "            if text:\n",
    "                try:\n",
    "                    index = curatedFiles[curatedField]['lookup'][lookupHash]\n",
    "                    match = curatedFiles[curatedField]['content'][index]\n",
    "\n",
    "                    for column in match: \n",
    "                        if column != 'id':\n",
    "                            newSubfield = etree.SubElement(valueTag, column)\n",
    "                            newSubfield.text = match[column]\n",
    "                except:\n",
    "                    print(\"Could not find matching data for\", valueTag.find('text').text)\n",
    "    return record\n",
    "\n",
    "def addImageData(record):\n",
    "    recordIdentifier = record.find('record-identifier').text\n",
    "    try:\n",
    "        imageData = imagesData[recordIdentifier]\n",
    "    except:\n",
    "        print(\"Could not find an image for\", recordIdentifier)\n",
    "        return record\n",
    "    \n",
    "    imageTag = etree.SubElement(record, 'image')\n",
    "    imageTag.set('filename', imageData['filename'])\n",
    "    imageTag.text = imageData['image_id']\n",
    "    return record\n",
    "\n",
    "def addRecordIdentifier(record):\n",
    "    identifier = record.find(\"InvNr\").text\n",
    "    field = etree.SubElement(record, \"record-identifier\")\n",
    "    field.text = identifier\n",
    "    return record\n",
    "\n",
    "def cleanKeyForTags(key):\n",
    "    cleanedKey = re.sub(r'[\\s.*_]', '', key)\n",
    "    cleanedKey = re.sub(r'[()]', '-', cleanedKey)\n",
    "    cleanedKey = re.sub(r'-$', '', cleanedKey)\n",
    "    return cleanedKey\n",
    "    \n",
    "def customHash(l):\n",
    "    def NFD(s):\n",
    "        return unicodedata.normalize('NFD', s)\n",
    "\n",
    "    return hash(NFD(json.dumps(l, ensure_ascii=False)))\n",
    "\n",
    "def convertRowToXMLRecord(row):\n",
    "    record = etree.Element('record')\n",
    "    for k in row.keys():\n",
    "        if k:\n",
    "            tag = cleanKeyForTags(k)\n",
    "            subElement = etree.SubElement(record, tag)\n",
    "            subElement.text = row[k]\n",
    "    return record\n",
    "\n",
    "def splitMultiValueFields(record):\n",
    "    multiValueSeparators = {\n",
    "        \"KünsterIn\": \"/\",\n",
    "        \"Bemerkungen\": \"/\",\n",
    "        \"Keywords\": \",\",\n",
    "        \"Ortsbezug\": r\"\\)[,|;]\"\n",
    "    }\n",
    "    # Add suffix that may be cut off through regex separator\n",
    "    multiValueSuffixes = {\n",
    "        \"Ortsbezug\": \")\"\n",
    "    }\n",
    "    for key in multiValueSeparators.keys():\n",
    "        tag = record.find(cleanKeyForTags(key))\n",
    "        values = re.split(multiValueSeparators[key], tag.text)\n",
    "        values = [d.strip() for d in values]\n",
    "        if key in multiValueSuffixes.keys():\n",
    "            values = [d + multiValueSuffixes[key] for d in values[:-1]] + values[-1:]\n",
    "        \n",
    "        valuesTag = etree.SubElement(tag, 'values')\n",
    "        for value in values:\n",
    "            valueTag = etree.SubElement(valuesTag, 'value')\n",
    "            etree.SubElement(valueTag, 'text').text = value\n",
    "\n",
    "        tag.text = ''\n",
    "        \n",
    "    return record "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputData = []\n",
    "with open(inputFile, 'r') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        inputData.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read fields from external files\n",
    "\n",
    "curatedFiles = {}\n",
    "\n",
    "for key in curatedFields:\n",
    "    filename = curatedFilesPre + key.lower() + '.csv'\n",
    "    try:\n",
    "        content = []\n",
    "        with open(filename, 'r') as f:\n",
    "            reader = csv.DictReader(f)\n",
    "            for row in reader:\n",
    "                content.append(row)\n",
    "\n",
    "        lookup = {}\n",
    "        for i, row in enumerate(content):\n",
    "            lookupHash = customHash(row['id'])\n",
    "            lookup[lookupHash] = i\n",
    "\n",
    "        curatedFiles[key] = {\n",
    "            \"tag\": cleanKeyForTags(key),\n",
    "            \"content\": content,\n",
    "            \"lookup\": lookup,\n",
    "            \"filename\" : filename\n",
    "        }\n",
    "\n",
    "    except:\n",
    "        print(\"Could not process\", filename)\n",
    "\n",
    "artistsData = []\n",
    "\n",
    "with open(artistsFile, 'r') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        artistsData.append(row)\n",
    "        \n",
    "imagesData = {}\n",
    "\n",
    "with open(imagesFile, 'r') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        imagesData[row['record_id']] = {\n",
    "            'image_id': row['image_id'],\n",
    "            'filename': row['filename']\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 689.84it/s]\n"
     ]
    }
   ],
   "source": [
    "collection = etree.XML(\"<collection/>\")\n",
    "\n",
    "for row in tqdm(inputData[offset:offset + limit]):\n",
    "    record = convertRowToXMLRecord(row)\n",
    "    \n",
    "    record = addRecordIdentifier(record)\n",
    "    record = splitMultiValueFields(record)\n",
    "    record = addArtistsData(record)\n",
    "    record = addImageData(record)\n",
    "    record = addCuratedData(record)\n",
    "    \n",
    "    collection.clear()\n",
    "    collection.append(record)\n",
    "    outputFile = outputDirectory + outputPrefix + record.find(\"InvNr\").text + \".xml\"\n",
    "    with open(outputFile, 'wb') as f:\n",
    "        f.write(etree.tostring(collection, xml_declaration=True, encoding='UTF-8', pretty_print=True))\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
