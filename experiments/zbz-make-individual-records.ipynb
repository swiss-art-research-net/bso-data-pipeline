{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from edtf import parse_edtf\n",
    "\n",
    "from sariDateParser.dateParser import parse\n",
    "from lxml import etree\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import csv\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "import urllib\n",
    "import unicodedata\n",
    "import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/Users/fkraeutli/Sites/bso-data-pipeline/scripts/helpers\")\n",
    "import dateOverrides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputFiles = [\n",
    "    '../data/source/BIBLIOGRAPHIC_8971984070005508_1.xml',\n",
    "    '../data/source/BIBLIOGRAPHIC_8971984070005508_2.xml',\n",
    "    '../data/source/BIBLIOGRAPHIC_8971984070005508_3.xml',\n",
    "    '../data/source/BIBLIOGRAPHIC_8971984070005508_4.xml'\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "curatedFilesPre = '../data/source/zbz-curation-'\n",
    "manifestDirectory = \"../data/manifests/\"\n",
    "doisFile = '../data/source/zbz-dois.csv'\n",
    "outputDirectory = \"output/\"\n",
    "outputPrefix = \"zbz-record-\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List fields that contain dates. Those will be passed to the parser\n",
    "fieldsContainingDates = ['100$d', '260$c', '260$g', '264$c', '533$d', '600$d', '611$d', '700$d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "curatedFields = {\n",
    "    '100': [['a', 'd']],\n",
    "    '110': [['a']],\n",
    "    '264': [['a'], ['b']],\n",
    "    '600': [['a', 'b']],\n",
    "    '610': [['a', 'g']],\n",
    "    '611': [['a', 'c', 'd']],\n",
    "    '650': [['a', 'g']],\n",
    "    '651': [['a', 'g']],\n",
    "    '655': [['a']],\n",
    "    '700': [['a', 'd']],\n",
    "    '710': [['a']],\n",
    "    '751': [['a', 'g']]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit=10\n",
    "offset=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "def addCuratedData(record):\n",
    "    datafields = record.findall(\"datafield\")\n",
    "    # Look through every datafield\n",
    "    for datafield in datafields:\n",
    "        tag = datafield.get(\"tag\")\n",
    "        # Check if datafield has been curated\n",
    "        if tag in curatedFields.keys():\n",
    "            for subfieldList in curatedFields[tag]:\n",
    "                curatedFileId = tag + \"-\" + '_'.join(subfieldList)\n",
    "                \n",
    "                conditions = {}\n",
    "                for subfield in subfieldList:\n",
    "                    value = datafield.find(\"subfield[@code='%s']\" % subfield)\n",
    "                    value = value.text if value is not None else \"\"\n",
    "                    conditions[tag + \"_\" + subfield] = value\n",
    "                \n",
    "                lookupHash = customHash(list(conditions.values()))\n",
    "        \n",
    "                if not set(list(conditions.values())) == {''}: # Skip if the condition is empty\n",
    "                    try:\n",
    "                        index = curatedFiles[curatedFileId]['lookup'][lookupHash]\n",
    "                        match = curatedFiles[curatedFileId]['content'][index]\n",
    "\n",
    "                        for column in match: \n",
    "                            if column not in conditions:\n",
    "                                newSubfield = etree.SubElement(datafield, \"subfield\")\n",
    "                                newSubfield.set(\"code\", column)\n",
    "                                newSubfield.text = match[column]\n",
    "                    except:\n",
    "                        print(\"Nothing found for\", conditions, lookupHash, record.find(\"controlfield[@tag='001']\").text)\n",
    "    \n",
    "    return record\n",
    "\n",
    "\n",
    "def addImages(record):\n",
    "    if record.find(\"datafield[@tag='manifest']\") is not None:\n",
    "        images = getImagesFromCachedManifest(record.find(\"datafield[@tag='manifest']\").text)\n",
    "        if images:\n",
    "            record.append(imageListToXml(images))\n",
    "    return record\n",
    "\n",
    "def addRecordIdentifier(record):\n",
    "    identifier = record.find(\"controlfield[@tag='001']\").text\n",
    "    field = etree.SubElement(record, \"record-identifier\")\n",
    "    field.text = \"zbz-\" + identifier\n",
    "    return record\n",
    "\n",
    "def addManifest(record):\n",
    "    identifier = record.find(\"controlfield[@tag='001']\").text\n",
    "    try:\n",
    "        manifestURL = manifests[identifier]\n",
    "    except:\n",
    "        print(\"Could not find IIIF manifest for\", identifier)\n",
    "        return record\n",
    "    \n",
    "    manifestDatafield = etree.SubElement(record, \"datafield\")\n",
    "    manifestDatafield.set(\"tag\", \"manifest\")\n",
    "    manifestDatafield.text = manifestURL\n",
    "    return record\n",
    "\n",
    "def convertEDTFdate(date):\n",
    "    try:\n",
    "        d = parse_edtf(downgradeEDTF(date))\n",
    "    except:\n",
    "        raise ValueError('Invalid date', date)\n",
    "    \n",
    "    if 'Interval' in str(type(d)):\n",
    "        if type(d.lower) is list:\n",
    "            lower = d.lower[0].lower_strict()\n",
    "        else:\n",
    "            lower = d.lower.lower_strict()\n",
    "        if type(d.upper) is list:\n",
    "            upper = d.upper[0].upper_strict()\n",
    "        else:\n",
    "            upper = d.upper.upper_strict()\n",
    "    else:\n",
    "        if type(d) is list:\n",
    "            lower = d[0].lower_strict()\n",
    "            upper = d[0].upper_strict()\n",
    "        else:\n",
    "            lower = d.lower_strict()\n",
    "            upper = d.upper_strict()\n",
    "    return {\n",
    "        'lower': time.strftime(\"%Y-%m-%d\", lower),\n",
    "        'upper': time.strftime(\"%Y-%m-%d\", upper)\n",
    "    }\n",
    "\n",
    "\n",
    "def customHash(l):\n",
    "    def NFKD(s):\n",
    "        return unicodedata.normalize('NFKD', s)\n",
    "\n",
    "    return hash(NFKD(json.dumps(l, ensure_ascii=False)))\n",
    "\n",
    "def downgradeEDTF(date):\n",
    "    \"\"\"\n",
    "    Convert a edtf date string to the previous version supported by the python edtf package\n",
    "    \"\"\"\n",
    "    edtfDate = date.replace('X','u')\n",
    "    if edtfDate[-1:] == '/':\n",
    "        edtfDate += 'uuuu-uu'\n",
    "    if edtfDate[0] == '/':\n",
    "        edtfDate = 'uuuu-uu' + edtfDate\n",
    "    return edtfDate\n",
    "\n",
    "def getImagesFromCachedManifest(manifest):\n",
    "    manifestFilePath = manifestDirectory + urllib.parse.quote(manifest, safe='') + '.json'\n",
    "    if os.path.isfile(manifestFilePath):\n",
    "        with open(manifestFilePath, 'r') as f:\n",
    "            content = json.load(f)\n",
    "            if 'sequences' in content and len(content['sequences']) > 0:\n",
    "                canvases = [d for d in content['sequences'][0]['canvases']]\n",
    "                images = [{\n",
    "                    'image': c['images'][0]['resource']['service']['@id'],\n",
    "                    'width': c['width'],\n",
    "                    'height': c['height']\n",
    "                } for c in canvases]\n",
    "                return images\n",
    "            else:\n",
    "                print(\"No sequences found in manifest %s\" % manifest)\n",
    "    else:\n",
    "        print(\"Manifest %s has not been cached\" % manifest)\n",
    "    \n",
    "def imageListToXml(images):\n",
    "    imagesNode = etree.Element(\"images\")\n",
    "    for image in images:\n",
    "        imageNode = etree.SubElement(imagesNode, \"image\")\n",
    "        etree.SubElement(imageNode, \"height\").text = str(image['height'])\n",
    "        etree.SubElement(imageNode, \"width\").text = str(image['width'])\n",
    "        etree.SubElement(imageNode, \"url\", type=\"iiif\").text = image['image']\n",
    "    return imagesNode\n",
    "\n",
    "def parseDate(date):\n",
    "    if date in dateOverrides.zbz:\n",
    "        return dateOverrides.zbz[date]\n",
    "    else:\n",
    "        return parse(date)\n",
    "\n",
    "def processDates(record):\n",
    "    for dateField in fieldsContainingDates:\n",
    "        parts = dateField.split('$')\n",
    "        xpath = \"datafield[@tag='%s']/subfield[@code='%s']\" % (parts[0], parts[1])\n",
    "        subfields = record.findall(xpath)\n",
    "        if subfields is not None:\n",
    "            for subfield in subfields:\n",
    "                try:\n",
    "                    parsedDate = parseDate(subfield.text)\n",
    "                except:\n",
    "                    print(\"Could not parse date\")\n",
    "                if parsedDate:\n",
    "                    subfield.set(\"parsedDate\", parsedDate)\n",
    "                    daterange = convertEDTFdate(parsedDate)\n",
    "                    subfield.set(\"upperDate\", daterange['upper'])\n",
    "                    subfield.set(\"lowerDate\", daterange['lower'])\n",
    "    return record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = etree.XML(\"<collection/>\")\n",
    "for inputFile in inputFiles:\n",
    "    collection = etree.parse(inputFile)\n",
    "    for record in collection.findall(\"//record\"):\n",
    "        root.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "curatedFiles = {}\n",
    "for tag in curatedFields.keys():\n",
    "    for subfieldList in curatedFields[tag]:\n",
    "        subfieldListId = '_'.join(subfieldList)\n",
    "        \n",
    "        filename = curatedFilesPre + tag + '-' + subfieldListId + '.csv'\n",
    "        try:\n",
    "            content = []\n",
    "            with open(filename, 'r') as f:\n",
    "                reader = csv.DictReader(f)\n",
    "                for row in reader:\n",
    "                    content.append(row)\n",
    "            \n",
    "            lookup = {}\n",
    "            for i, row in enumerate(content):\n",
    "                lookupHash = customHash([row[tag + '_' + subfield] for subfield in subfieldList])\n",
    "                lookup[lookupHash] = i\n",
    "            \n",
    "            curatedFiles[tag + \"-\" + subfieldListId] = {\n",
    "                \"tag\": tag,\n",
    "                \"content\": content,\n",
    "                \"lookup\": lookup,\n",
    "                \"subfields\" : subfieldList,\n",
    "                \"filename\" : filename\n",
    "            }\n",
    "                \n",
    "        except:\n",
    "            print(\"Could not process\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifests = {}\n",
    "with open(doisFile, 'r') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        manifests[row['id']] = row['manifest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = root.findall(\".//record\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = root\n",
    "\n",
    "idsToExtract = ['003639920','005134689','005219259','005300655','005203731', '010200392']\n",
    "newIds = ['99' + d + '0205508' for d in idsToExtract ] + ['990104610240205508']\n",
    "\n",
    "newIds = ['990104479200205508']\n",
    "\n",
    "def splitMultiValueFields(record):\n",
    "    # Adds separate datafields for datafields that contain multiple values\n",
    "    # e.g. 264 sometimes contains several subfields with code a and b\n",
    "    # Find subfields that have at least 2 code a's\n",
    "    subfieldAInSecondPlace = record.xpath(\"datafield/subfield[@code='a'][2]\")\n",
    "    for subfield in subfieldAInSecondPlace:\n",
    "        datafield = subfield.getparent()\n",
    "        tag = datafield.get(\"tag\")\n",
    "        # Determine the number of subfields by looking at the number of subfields with code a\n",
    "        numSubfields = len(datafield.findall(\"subfield[@code='a']\"))\n",
    "        # Determine the codes that are used\n",
    "        codes = sorted(list(set([d.get('code') for d in datafield.findall(\"subfield\")])))\n",
    "        # For every subfield\n",
    "        for i in range(numSubfields):\n",
    "            index = i+1\n",
    "            # Add a new subfield\n",
    "            newDatafield = etree.SubElement(record, \"datafield\")\n",
    "            newDatafield.set(\"tag\", tag)\n",
    "            # Mark the index of the subfield\n",
    "            indexSubfield = etree.SubElement(newDatafield, \"subfield\")\n",
    "            indexSubfield.set(\"code\", \"index\")\n",
    "            indexSubfield.text = str(i)\n",
    "            # Iterate through the subfield codes and if there is a subfield at the\n",
    "            # respective index, add it\n",
    "            for code in codes:\n",
    "                value = datafield.xpath(\"subfield[@code='%s'][%d]\" % (code, index))\n",
    "                if value is not None and len(value):\n",
    "                    newSubfield = etree.SubElement(newDatafield, \"subfield\")\n",
    "                    newSubfield.set(\"code\", code)\n",
    "                    newSubfield.text = value[0].text\n",
    "        # Remove the parent\n",
    "        record.remove(datafield)\n",
    "    \n",
    "    return record\n",
    "\n",
    "def processRecord(record):\n",
    "    record = addRecordIdentifier(record)\n",
    "    record = splitMultiValueFields(record)\n",
    "    record = addCuratedData(record)\n",
    "    record = addManifest(record)\n",
    "    record = addImages(record)\n",
    "    record = processDates(record)\n",
    "    return record\n",
    "\n",
    "def saveRecord(record):\n",
    "    collection.clear()\n",
    "    collection.append(record)\n",
    "    outputFile = outputDirectory + outputPrefix + record.find(\"controlfield[@tag='001']\").text + \".xml\"\n",
    "    with open(outputFile, 'wb') as f:\n",
    "        f.write(etree.tostring(collection, xml_declaration=True, encoding='UTF-8', pretty_print=True))\n",
    "        f.close()\n",
    "        \n",
    "        \n",
    "for record in [d for d in records if d.find(\"controlfield[@tag='001']\").text in newIds]:\n",
    "    record = processRecord(record)\n",
    "    saveRecord(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
